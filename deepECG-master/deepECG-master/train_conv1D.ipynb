{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'data/training2017/'\n",
    "LABEL_PATH = data_path + 'REFERENCE.csv'\n",
    "\n",
    "# lower bound of the length of the signal\n",
    "LB_LEN_MAT = 100\n",
    "\n",
    "# upper bound of the length of the signal\n",
    "UB_LEN_MAT = 10100\n",
    "\n",
    "LABELS = [\"N\", \"A\", \"O\"]\n",
    "n_classes = len(LABELS) + 1\n",
    "\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_of_mat(mat_filename):    \n",
    "    \"\"\"\n",
    "    load the mat file and return the data.\n",
    "    sio.loadmat returns a dict and 'val' means value.\n",
    "    \"\"\"\n",
    "    \n",
    "    return sio.loadmat(mat_filename)[\"val\"][0, :]\n",
    "\n",
    "def len_of_mat(mat_filename):\n",
    "    return len(value_of_mat(mat_filename))\n",
    "\n",
    "def plot_ecg(mat_filename, time_interval=1000):\n",
    "    ecg_signal = list(value_of_mat(mat_filename))\n",
    "    plt.plot(ecg_signal[:time_interval])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training size is  8528\n"
     ]
    }
   ],
   "source": [
    "files = [f for f in os.listdir(data_path) if os.path.isfile(os.path.join(data_path, f))]\n",
    "\n",
    "mat_files = [f for f in files if f.startswith(\"A\") and f.endswith('.mat')]\n",
    "\n",
    "# filter out short mat_files\n",
    "mat_files = [f for f in mat_files if len_of_mat(os.path.join(data_path, f)) >= LB_LEN_MAT]\n",
    "\n",
    "n_sample = len(mat_files)\n",
    "print('Total training size is ', n_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load signals as x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def duplicate_padding(signals, UB_LEN_MAT):\n",
    "    \"\"\"\n",
    "    padding the signals not with zeros but the copy of the signal.\n",
    "    \n",
    "    :param: signals: list of np.array with 1 dimension.\n",
    "        more general, it should be a list of objects, which has length and can be concatenate.\n",
    "    :param: UB_LEN_MAT: int\n",
    "    \"\"\"\n",
    "    \n",
    "    X = np.zeros((len(signals), UB_LEN_MAT))\n",
    "    for i, sig in enumerate(signals):\n",
    "        if  len(sig) >= UB_LEN_MAT:\n",
    "            X[i, :] = sig[0: UB_LEN_MAT]\n",
    "        else:\n",
    "            sig_copy_section = sig[0: (UB_LEN_MAT - len(sig))]\n",
    "            sig_replay = np.hstack((sig, sig_copy_section))  # np.concatenate()\n",
    "\n",
    "            # concatenate copied signal to original signal until its length meets the upper bound\n",
    "            while len(sig_replay) < UB_LEN_MAT:\n",
    "                sig_copy_section = sig[0:(UB_LEN_MAT - len(sig_replay))]\n",
    "                sig_replay = np.hstack((sig_replay, sig_copy_section))\n",
    "\n",
    "            X[i, :] = sig_replay\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "signals = [value_of_mat(os.path.join(DATA_PATH, f)) for f in mat_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = duplicate_padding(signals, UB_LEN_MAT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load labels as Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num2onehot(number, length):\n",
    "    x = np.zeros(length)\n",
    "    x[number] = 1\n",
    "    return x\n",
    "\n",
    "def num2onehot_for_list(a_list):\n",
    "    length = max(a_list) + 1\n",
    "    return np.array([num2onehot(number, length) for number in a_list])\n",
    "\n",
    "def onehot2num_for_list(onehot_array):\n",
    "    return [list(onehot).index(1) for onehot in onehot_array]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label = pd.read_csv(label_path, sep=',', header=None, names=None)\n",
    "df_label.columns = [\"sigID\", \"label\"]\n",
    "df_label = df_label.set_index(\"sigID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_IDs = [f.split(\".\")[0] for f in mat_files]\n",
    "labels = [df_label.loc[sigID, \"label\"] for sigID in signal_IDs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_ids = [LABELS.index(l) if l in LABELS else 3 for l in labels]\n",
    "Y = num2onehot_for_list(label_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# some data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = (X - X.mean())/(X.std()) \n",
    "X = np.expand_dims(X, axis=2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# shuffle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = [i for i in range(len(X))]\n",
    "permutations = np.random.permutation(values)\n",
    "X = X[permutations, :]\n",
    "Y = Y[permutations, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_ratio = 0.9\n",
    "\n",
    "X_train = X[:int(train_test_ratio * n_sample), :]\n",
    "Y_train = Y[:int(train_test_ratio * n_sample), :]\n",
    "X_test  = X[int(train_test_ratio * n_sample):, :]\n",
    "Y_test  = Y[int(train_test_ratio * n_sample):, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load model and train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.Conv1d import Conv1d\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Conv1d(UB_LEN_MAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = ModelCheckpoint(filepath='./trained_models/Best_model.h5',\n",
    "                               monitor='val_acc',\n",
    "                               verbose=1,\n",
    "                               save_best_only=True)\n",
    "\n",
    "# print(\"x shape\", X_train.shape)\n",
    "# print(\"y shape\", Y_train.shape)\n",
    "\n",
    "hist = model.fit(X_train, Y_train,\n",
    "                 validation_data=(X_test, Y_test),\n",
    "                 batch_size=275,\n",
    "                 epochs=3,\n",
    "                 verbose=2,\n",
    "                 shuffle=True,\n",
    "                 callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = accuracy_score(onehot2num_for_list(Y_test), predictions.argmax(axis=1))\n",
    "print('Last epoch\\'s validation score is ', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save some results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(predictions.argmax(axis=1))\n",
    "df.to_csv('./trained_models/Preds_' + str(format(score, '.4f')) + '.csv', index=None, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = confusion_matrix(onehot2num_for_list(Y_test), predictions.argmax(axis=1))\n",
    "df = pd.DataFrame(confusion_matrix)\n",
    "df.to_csv('./trained_models/Result_Conf' + str(format(score, '.4f')) + '.csv', index=None, header=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "congyuml",
   "language": "python",
   "name": "congyuml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
